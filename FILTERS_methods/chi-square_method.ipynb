{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "291ca22a",
   "metadata": {},
   "source": [
    "# ‚úÖ Chi-Square Feature Selection (Categorical Data)\n",
    "\n",
    "This method is **specifically designed for categorical features + categorical target**.\n",
    "\n",
    "If your data looks like:\n",
    "\n",
    "* encoded categorical features (0/1)\n",
    "* target = 0/1\n",
    "\n",
    "üëâ **Chi-square is PERFECT**.\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Core intuition (very simple)\n",
    "\n",
    "Chi-square checks:\n",
    "\n",
    "> ‚ÄúIs this feature actually related to the target\n",
    "> or are they independent?‚Äù\n",
    "\n",
    "If feature and target are **independent** ‚Üí ‚ùå useless\n",
    "If they are **dependent** ‚Üí ‚úÖ useful\n",
    "\n",
    "---\n",
    "\n",
    "## üß© Real-life example\n",
    "\n",
    "Imagine spam dataset:\n",
    "\n",
    "| has_link | spam |\n",
    "| -------- | ---- |\n",
    "| 1        | 1    |\n",
    "| 1        | 1    |\n",
    "| 1        | 1    |\n",
    "| 0        | 0    |\n",
    "| 0        | 0    |\n",
    "\n",
    "Strong relationship ‚Üí very useful feature.\n",
    "\n",
    "But:\n",
    "\n",
    "| has_emoji | spam |\n",
    "| --------- | ---- |\n",
    "| 0         | 1    |\n",
    "| 0         | 0    |\n",
    "| 0         | 1    |\n",
    "| 0         | 0    |\n",
    "\n",
    "No relation ‚Üí useless.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö†Ô∏è Very important rule (INTERVIEW FAVORITE)\n",
    "\n",
    "> Chi-square works only with **non-negative values**\n",
    "\n",
    "That‚Äôs why we apply it **after one-hot encoding**.\n",
    "\n",
    "Binary values (0/1) ‚Üí perfect.\n",
    "\n",
    "---\n",
    "\n",
    "## üß† What chi-square actually measures\n",
    "\n",
    "It compares:\n",
    "\n",
    "* observed frequency\n",
    "  vs\n",
    "* expected frequency\n",
    "\n",
    "If difference is large ‚Üí feature matters.\n",
    "\n",
    "You don‚Äôt need math ‚Äî intuition is enough.\n",
    "\n",
    "---\n",
    "\n",
    "## üî• Practical example (hands-on)\n",
    "\n",
    "### Step 1 ‚Äî Dataset\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    \"city\": [\"Delhi\", \"Mumbai\", \"Delhi\", \"Delhi\", \"Mumbai\", \"Delhi\"],\n",
    "    \"gender\": [\"Male\", \"Female\", \"Male\", \"Male\", \"Female\", \"Male\"],\n",
    "    \"device\": [\"Android\", \"Android\", \"iPhone\", \"Android\", \"Android\", \"iPhone\"],\n",
    "    \"purchased\": [1, 0, 1, 1, 0, 0]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Step 2 ‚Äî One-hot encode\n",
    "\n",
    "```python\n",
    "df_encoded = pd.get_dummies(df, drop_first=False)\n",
    "\n",
    "X = df_encoded.drop(\"purchased\", axis=1)\n",
    "y = df_encoded[\"purchased\"]\n",
    "```\n",
    "\n",
    "Now everything is numeric (0/1).\n",
    "\n",
    "---\n",
    "\n",
    "### Step 3 ‚Äî Apply Chi-Square\n",
    "\n",
    "```python\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "chi_scores, p_values = chi2(X, y)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Step 4 ‚Äî See results clearly\n",
    "\n",
    "```python\n",
    "chi_df = pd.DataFrame({\n",
    "    \"feature\": X.columns,\n",
    "    \"chi_score\": chi_scores,\n",
    "    \"p_value\": p_values\n",
    "}).sort_values(\"chi_score\", ascending=False)\n",
    "\n",
    "chi_df\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üß† How to interpret output\n",
    "\n",
    "### Chi-score:\n",
    "\n",
    "* higher = stronger relationship\n",
    "\n",
    "### p-value:\n",
    "\n",
    "* < 0.05 ‚Üí important\n",
    "* > 0.05 ‚Üí likely useless\n",
    "\n",
    "Example:\n",
    "\n",
    "| feature       | chi_score | p_value |\n",
    "| ------------- | --------- | ------- |\n",
    "| device_iPhone | 6.21      | 0.01 ‚úÖ  |\n",
    "| city_Mumbai   | 0.02      | 0.88 ‚ùå  |\n",
    "\n",
    "---\n",
    "\n",
    "## üî• Feature selection using SelectKBest\n",
    "\n",
    "Instead of manually checking:\n",
    "\n",
    "```python\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "selector = SelectKBest(score_func=chi2, k=3)\n",
    "\n",
    "X_selected = selector.fit_transform(X, y)\n",
    "\n",
    "selected_features = X.columns[selector.get_support()]\n",
    "selected_features\n",
    "```\n",
    "\n",
    "Boom üí•\n",
    "Top K categorical features selected.\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Why Chi-Square is powerful\n",
    "\n",
    "‚úÖ perfect for categorical data\n",
    "‚úÖ measures real dependency\n",
    "‚úÖ fast\n",
    "‚úÖ interpretable\n",
    "‚úÖ commonly used in NLP\n",
    "‚úÖ widely asked in interviews\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ùå When NOT to use Chi-Square\n",
    "\n",
    "* continuous target (regression)\n",
    "* negative feature values\n",
    "* raw text\n",
    "* scaled data with negatives\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Interview-ready answer\n",
    "\n",
    "> ‚ÄúChi-square feature selection evaluates statistical dependency between categorical features and categorical target by comparing observed and expected frequencies.‚Äù\n",
    "\n",
    "üî• That line = strong impression.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö° Summary (crystal clear)\n",
    "\n",
    "* categorical features ‚Üí encode first\n",
    "* target must be categorical\n",
    "* values must be non-negative\n",
    "* higher chi-score = more useful\n",
    "* p-value confirms significance\n",
    "\n",
    "---\n",
    "\n",
    "## üß† You now know:\n",
    "\n",
    "‚úÖ Variance Threshold ‚Üí removes useless columns\n",
    "‚úÖ Chi-Square ‚Üí finds relevant categorical features\n",
    "\n",
    "This is **real feature selection pipeline**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d0e9379",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    \"city\": [\"Delhi\", \"Mumbai\", \"Delhi\", \"Delhi\", \"Mumbai\", \"Delhi\"],\n",
    "    \"gender\": [\"Male\", \"Female\", \"Male\", \"Male\", \"Female\", \"Male\"],\n",
    "    \"device\": [\"Android\", \"Android\", \"iPhone\", \"Android\", \"Android\", \"iPhone\"],\n",
    "    \"purchased\": [1, 0, 1, 1, 0, 0]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1779eb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = pd.get_dummies(df,drop_first=False)\n",
    "X = df_encoded.drop('purchased',axis=1)\n",
    "y = df['purchased']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2acc059c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "chi_score , p_values = chi2(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c83e2737",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_sqr = pd.DataFrame({\n",
    "    \"features\":X.columns,\n",
    "    \"chi_score\":chi_score,\n",
    "    \"p_value\":p_values\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d52015f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>chi_score</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>city_Delhi</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.317311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>city_Mumbai</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.157299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gender_Female</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.157299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gender_Male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.317311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>device_Android</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>device_iPhone</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         features  chi_score   p_value\n",
       "0      city_Delhi        1.0  0.317311\n",
       "1     city_Mumbai        2.0  0.157299\n",
       "2   gender_Female        2.0  0.157299\n",
       "3     gender_Male        1.0  0.317311\n",
       "4  device_Android        0.0  1.000000\n",
       "5   device_iPhone        0.0  1.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi_sqr\n",
    "'''Chi-score:\n",
    "higher = stronger relationship\n",
    "p-value:\n",
    "< 0.05 ‚Üí important\n",
    "0.05 ‚Üí likely useless'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c073965",
   "metadata": {},
   "source": [
    "## üìä Your Chi-Square Output\n",
    "\n",
    "| feature        | chi_score | p_value |\n",
    "| -------------- | --------- | ------- |\n",
    "| city_Delhi     | 1.0       | 0.317   |\n",
    "| city_Mumbai    | 2.0       | 0.157   |\n",
    "| gender_Female  | 2.0       | 0.157   |\n",
    "| gender_Male    | 1.0       | 0.317   |\n",
    "| device_Android | 0.0       | 1.000   |\n",
    "| device_iPhone  | 0.0       | 1.000   |\n",
    "\n",
    "---\n",
    "\n",
    "# üß† RULES TO DECIDE (memorize these)\n",
    "\n",
    "### ‚úÖ Rule 1 ‚Äî p-value is KING\n",
    "\n",
    "> If **p-value < 0.05 ‚Üí keep**\n",
    "> If **p-value ‚â• 0.05 ‚Üí remove**\n",
    "\n",
    "Why?\n",
    "\n",
    "Because p-value tells:\n",
    "\n",
    "> ‚ÄúIs this relationship statistically significant or just random?‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "## Apply rule üëá\n",
    "\n",
    "### ‚ùå device_Android\n",
    "\n",
    "* p = 1.0\n",
    "* means **completely independent**\n",
    "* target does not care at all\n",
    "\n",
    "‚ùå REMOVE\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ùå device_iPhone\n",
    "\n",
    "* p = 1.0\n",
    "* zero relationship\n",
    "\n",
    "‚ùå REMOVE\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ùå city_Delhi\n",
    "\n",
    "* p = 0.317 (> 0.05)\n",
    "\n",
    "‚ùå REMOVE\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ùå gender_Male\n",
    "\n",
    "* p = 0.317 (> 0.05)\n",
    "\n",
    "‚ùå REMOVE\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ö†Ô∏è city_Mumbai\n",
    "\n",
    "* p = 0.157 (> 0.05)\n",
    "* not statistically significant\n",
    "\n",
    "‚ùå REMOVE (for strict ML)\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ö†Ô∏è gender_Female\n",
    "\n",
    "* p = 0.157 (> 0.05)\n",
    "\n",
    "‚ùå REMOVE\n",
    "\n",
    "---\n",
    "\n",
    "## üî• FINAL RESULT\n",
    "\n",
    "üëâ **Statistically speaking:**\n",
    "\n",
    "### ‚ùå KEEP = NONE\n",
    "\n",
    "### ‚ùå REMOVE = ALL\n",
    "\n",
    "And that is **100% correct**.\n",
    "\n",
    "---\n",
    "\n",
    "## üòÆ Why everything got removed?\n",
    "\n",
    "Because your dataset is:\n",
    "\n",
    "* extremely small\n",
    "* very few samples\n",
    "* weak relationships\n",
    "* randomness dominates\n",
    "\n",
    "üìå Chi-square is **data-hungry**.\n",
    "\n",
    "With only 5‚Äì6 rows, statistics cannot prove dependency.\n",
    "\n",
    "---\n",
    "\n",
    "## üß† THIS IS A HUGE LEARNING MOMENT\n",
    "\n",
    "> Feature selection does NOT guarantee features will survive.\n",
    "\n",
    "Sometimes the correct answer is:\n",
    "\n",
    "> ‚ÄúNo feature is statistically significant.‚Äù\n",
    "\n",
    "That‚Äôs not failure ‚Äî that‚Äôs honesty.\n",
    "\n",
    "---\n",
    "\n",
    "## üî• VERY IMPORTANT REALITY\n",
    "\n",
    "In real datasets (10k+ rows):\n",
    "\n",
    "* p-values drop drastically\n",
    "* true relationships appear\n",
    "* chi-square becomes powerful\n",
    "\n",
    "In toy datasets ‚Üí almost always fails.\n",
    "\n",
    "---\n",
    "\n",
    "## üß† How professionals decide in practice\n",
    "\n",
    "### Option 1 ‚Äî Strict statistical approach\n",
    "\n",
    "Used in:\n",
    "\n",
    "* medical ML\n",
    "* finance\n",
    "* research\n",
    "\n",
    "Rule:\n",
    "\n",
    "```\n",
    "p_value < 0.05\n",
    "```\n",
    "\n",
    "Your result ‚Üí keep none ‚úÖ\n",
    "\n",
    "---\n",
    "\n",
    "### Option 2 ‚Äî Practical ML approach (very common)\n",
    "\n",
    "We combine **three things**:\n",
    "\n",
    "1. chi-score ranking\n",
    "2. domain logic\n",
    "3. model validation\n",
    "\n",
    "Example:\n",
    "\n",
    "Even if p = 0.15\n",
    "but business logic says device matters\n",
    "‚Üí we may keep it temporarily.\n",
    "\n",
    "---\n",
    "\n",
    "## üî• So what do we actually keep?\n",
    "\n",
    "### Practical rule:\n",
    "\n",
    "> Keep **top K features by chi-score**,\n",
    "> even if p-value slightly high.\n",
    "\n",
    "Example:\n",
    "\n",
    "```python\n",
    "chi_df.sort_values(\"chi_score\", ascending=False).head(2)\n",
    "```\n",
    "\n",
    "That would give:\n",
    "\n",
    "* city_Mumbai\n",
    "* gender_Female\n",
    "\n",
    "Then model decides later.\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Final professional rule (IMPORTANT)\n",
    "\n",
    "| Stage                   | What we do        |\n",
    "| ----------------------- | ----------------- |\n",
    "| Early feature selection | Loose rules       |\n",
    "| Final model             | Strict evaluation |\n",
    "| Cross-validation        | Final judge       |\n",
    "\n",
    "üëâ Feature selection is **not a one-shot decision**.\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Interview-perfect explanation\n",
    "\n",
    "If interviewer asks:\n",
    "\n",
    "> ‚ÄúWhat if all p-values are high?‚Äù\n",
    "\n",
    "You say:\n",
    "\n",
    "> ‚ÄúIt usually indicates small dataset or weak statistical power. In such cases, I rank features using chi-square scores and validate them using model performance instead of blindly dropping everything.‚Äù\n",
    "\n",
    "üî• That answer is VERY strong.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö° Crystal-clear summary\n",
    "\n",
    "* p-value < 0.05 ‚Üí statistically significant\n",
    "* your dataset is too small\n",
    "* chi-square cannot prove dependency\n",
    "* removing all features is mathematically correct\n",
    "* practically, we keep top-ranked features temporarily\n",
    "* final decision comes from model performance\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3a95f0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['city_Mumbai', 'gender_Female', 'gender_Male'], dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature selection using SelectKBest\n",
    "from sklearn.feature_selection import SelectKBest,chi2\n",
    "\n",
    "selector = SelectKBest(score_func=chi2,k=3)\n",
    "X_selected = selector.fit_transform(X,y)\n",
    "\n",
    "selected_features = X.columns[selector.get_support()]\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d50bab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
